{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b5c0-87cb-4302-8e3c-dc809d0039fb",
   "metadata": {},
   "source": [
    "# Understanding Memory in LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f73380-6395-4e9f-9c83-3f47a5d7e292",
   "metadata": {},
   "source": [
    "In the previous Notebook 03, we successfully explored how OpenAI models can enhance the results from Azure Cognitive Search. [Bing Chat](http://chat.bing.com/) is a search engine with a GPT-4 model that utilizes the content of search results to provide context and deliver accurate responses to queries.\n",
    "\n",
    "However, we have yet to discover how to engage in a conversation with the LLM. With Bing Chat, this is possible, as the LLM can understand and reference the previous responses.\n",
    "\n",
    "There is a common misconception that GPT models have memory. This is not true. While they possess knowledge, they do not retain information from previous questions asked to them.\n",
    "\n",
    "The aim of this Notebook is to demonstrate how we can \"provide memory\" to the LLM by utilizing prompts and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733c782e-204c-47d0-8dae-c9df7091ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from openai.error import OpenAIError\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    get_search_results,\n",
    "    order_search_results,\n",
    "    model_tokens_limit,\n",
    "    num_tokens_from_docs,\n",
    "    embed_docs,\n",
    "    search_docs,\n",
    "    get_answer,\n",
    ")\n",
    "\n",
    "from common.prompts import COMBINE_QUESTION_PROMPT, COMBINE_PROMPT, COMBINE_CHAT_PROMPT\n",
    "\n",
    "import logging\n",
    "\n",
    "# Get the root logger\n",
    "logger = logging.getLogger()\n",
    "# Set the logging level to a higher level to ignore INFO messages\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Don't mess with this unless you really know what you are doing\n",
    "AZURE_SEARCH_API_VERSION = '2021-04-30-Preview'\n",
    "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "\n",
    "# Change these below with your own services credentials\n",
    "AZURE_SEARCH_ENDPOINT =\"ENTER YOUR VALUE\"\n",
    "AZURE_SEARCH_KEY = \"ENTER YOUR VALUE\"\n",
    "AZURE_OPENAI_ENDPOINT = \"ENTER YOUR VALUE\"\n",
    "AZURE_OPENAI_API_KEY = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_ENDPOINT = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_NAME = \"ENTER YOUR VALUE\"\n",
    "AZURE_COSMOSDB_CONTAINER_NAME = \"ENTER YOUR VALUE\"\n",
    "AZURE_COMOSDB_CONNECTION_STRING = \"ENTER YOUR VALUE\" # Find this in the Keys section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc63c55-a57d-49a7-b6c7-0f18bca8199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION\n",
    "os.environ[\"AZURE_SEARCH_KEY\"] = AZURE_SEARCH_KEY\n",
    "os.environ[\"AZURE_SEARCH_ENDPOINT\"] = AZURE_SEARCH_ENDPOINT\n",
    "os.environ[\"AZURE_SEARCH_API_VERSION\"] = AZURE_SEARCH_API_VERSION\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"AZURE_COSMOSDB_ENDPOINT\"]=  AZURE_COSMOSDB_ENDPOINT\n",
    "os.environ[\"AZURE_COSMOSDB_NAME\"]=  AZURE_COSMOSDB_NAME\n",
    "os.environ[\"AZURE_COSMOSDB_CONTAINER_NAME\"]=  AZURE_COSMOSDB_CONTAINER_NAME\n",
    "os.environ[\"AZURE_COMOSDB_CONNECTION_STRING\"]=  AZURE_COMOSDB_CONNECTION_STRING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc72b22-11c2-4df0-91b8-033d01829663",
   "metadata": {},
   "source": [
    "### Let's start with the basics\n",
    "Let's use a very simple example to see if the GPT model of Azure OpenAI have memory. We again will be using langchain to simplify our code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eef5dc9-8b80-4085-980c-865fa41fa1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Tell me some use cases for reinforcement learning?\"\n",
    "FOLLOW_UP_QUESTION = \"Can you rephrase what you just said?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a00181d5-bd76-4ce4-a256-75ac5b58c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "MODEL = \"gpt-35-turbo\"\n",
    "# Create an OpenAI instance\n",
    "llm = AzureChatOpenAI(deployment_name=MODEL, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9502d0f1-fddf-40d1-95d2-a1461dcc498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a very simple prompt template, just the question as is:\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c9903e-15c7-4e05-87a1-58e5a7917ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Game playing: Reinforcement learning algorithms have been used to develop game playing agents that can learn to play games such as chess, Go, and poker.\n",
       "\n",
       "2. Robotics: Reinforcement learning has been used to train robots to perform tasks such as grasping objects, navigating environments, and manipulating objects.\n",
       "\n",
       "3. Autonomous driving: Reinforcement learning can be used to train autonomous vehicles to navigate complex environments and make decisions in real-time.\n",
       "\n",
       "4. Advertising: Reinforcement learning can be used to optimize online advertising campaigns by learning which ads and targeting strategies are most effective.\n",
       "\n",
       "5. Finance: Reinforcement learning can be used to develop trading algorithms that can learn to make profitable trades in financial markets.\n",
       "\n",
       "6. Healthcare: Reinforcement learning can be used to develop personalized treatment plans for patients based on their medical history and other factors.\n",
       "\n",
       "7. Resource management: Reinforcement learning can be used to optimize resource allocation in industries such as energy, transportation, and logistics.\n",
       "\n",
       "8. Education: Reinforcement learning can be used to develop personalized learning plans for students based on their learning history and progress."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the GPT model responds\n",
    "response = chain.run(QUESTION)\n",
    "printmd(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99acaf3c-ce68-4b87-b24a-6065b15ff9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I cannot rephrase what I just said as I do not have the capability to remember my previous statement. However, you can provide me with the statement you want me to rephrase, and I will do my best to provide an alternative wording.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's ask a follow up question\n",
    "chain.run(FOLLOW_UP_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1c143-c95f-4566-a8b4-af8c42f08dd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "As you can see, it doesn't remember what it just responded. This proof that the LLM does NOT have memory and that we need to give the memory as a a conversation history as part of the prompt, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0946ce71-6285-432e-b011-9c2dc1ba7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"question\"],\n",
    "    template=\"\"\"\n",
    "                {history}\n",
    "                Human: {question}\n",
    "                AI:\n",
    "            \"\"\"\n",
    "    )\n",
    "chain = LLMChain(llm=llm, prompt=hist_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d088e51-e5eb-4143-b87d-b2be429eb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_history = \"\"\"\n",
    "Human: {question}\n",
    "AI: {response}\n",
    "\"\"\".format(question=QUESTION, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d99e34ad-5539-44dd-b080-3ad05efd2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, here are some examples of how reinforcement learning can be applied:\\n\\n1. Game playing: Reinforcement learning algorithms can be used to create game-playing agents that can learn to play games like chess, Go, and poker.\\n\\n2. Robotics: Reinforcement learning can be used to train robots to perform tasks such as grasping objects, navigating environments, and manipulating objects.\\n\\n3. Autonomous driving: Reinforcement learning can help autonomous vehicles navigate complex environments and make real-time decisions.\\n\\n4. Advertising: Reinforcement learning can optimize online advertising campaigns by learning which ads and targeting strategies are most effective.\\n\\n5. Finance: Reinforcement learning can be used to develop trading algorithms that can learn to make profitable trades in financial markets.\\n\\n6. Healthcare: Reinforcement learning can be used to create personalized treatment plans for patients based on their medical history and other factors.\\n\\n7. Resource management: Reinforcement learning can optimize resource allocation in industries such as energy, transportation, and logistics.\\n\\n8. Education: Reinforcement learning can be used to create personalized learning plans for students based on their learning history and progress.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"history\":Conversation_history, \"question\": FOLLOW_UP_QUESTION})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e5af6-55d6-4353-b3f6-3275c95db00a",
   "metadata": {},
   "source": [
    "**Bingo!**, so we now know how to create a chatbot using LLMs, we just need to keep the state/history of the conversation and pass it as context every time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd1694-0077-4aa8-bd01-e9f763ce36a3",
   "metadata": {},
   "source": [
    "## Now that we understand the concept of memory via adding history as a context, let's go back to our GPT Smart Search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b27c45-7fbb-40da-a2e3-61e66a8e49b0",
   "metadata": {},
   "source": [
    "In order to not duplicate code, we have put many of the code used in Notebook 3 into functions. These functions are in the app/utils.py and app/prompts.py files This way we can use these functios in the app that we will build later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9f459b-e8b8-40b9-a94d-80c079968594",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1_name = \"cogsrch-index-files\"\n",
    "index2_name = \"cogsrch-index-csv\"\n",
    "indexes = [index1_name, index2_name]\n",
    "\n",
    "agg_search_results = get_search_results(QUESTION, indexes)\n",
    "ordered_results = order_search_results(agg_search_results, reranker_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2a3595-c3b7-4376-b9c5-0db7a42b3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom token limit for gpt-35-turbo : 3000\n",
      "Combined docs tokens count: 58744\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "for key,value in ordered_results.items():\n",
    "    for page in value[\"chunks\"]:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": value[\"location\"]}))\n",
    "\n",
    "# Calculate number of tokens of our docs\n",
    "tokens_limit = model_tokens_limit(MODEL)\n",
    "\n",
    "if(len(docs)>0):\n",
    "    num_tokens = num_tokens_from_docs(docs)\n",
    "    print(\"Custom token limit for\", MODEL, \":\", tokens_limit)\n",
    "    print(\"Combined docs tokens count:\",num_tokens)\n",
    "        \n",
    "else:\n",
    "    print(\"NO RESULTS FROM AZURE SEARCH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c26d7540-feb8-4581-849e-003f4bf2a601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 52\n",
      "Token count after similarity search: 3418\n",
      "Chain Type selected: map_reduce\n",
      "CPU times: user 263 ms, sys: 5.28 ms, total: 268 ms\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if num_tokens > tokens_limit:\n",
    "    index = embed_docs(docs)\n",
    "    top_docs = search_docs(index,QUESTION)\n",
    "    \n",
    "    # Now we need to recalculate the tokens count of the top results from similarity vector search\n",
    "    # in order to select the chain type: stuff or map_reduce\n",
    "    \n",
    "    num_tokens = num_tokens_from_docs(top_docs)   \n",
    "    print(\"Token count after similarity search:\", num_tokens)\n",
    "    chain_type = \"map_reduce\" if num_tokens > tokens_limit else \"stuff\"\n",
    "    \n",
    "else:\n",
    "    # if total tokens is less than our limit, we don't need to vectorize and do similarity search\n",
    "    top_docs = docs\n",
    "    chain_type = \"stuff\"\n",
    "    \n",
    "print(\"Chain Type selected:\", chain_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ce6efa9-2b8f-4810-904d-5986b4ae0372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning is finding use in many important applications, including routing, optimizing policies for tasks such as robotics, game playing, and decision making in complex environments. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the answer\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27501f1b-7db0-4ee3-9cb1-e609254ffa3d",
   "metadata": {},
   "source": [
    "And if we ask the follow up question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf5b323-3b9c-479b-8502-acfc4f7915dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first two excerpts do not contain relevant information to answer the question. The third excerpt discusses the differences between supervised learning and reinforcement learning. The fourth excerpt discusses the issue of reusing experience to learn about another policy in reinforcement learning. The authors present a method to estimate the value of policies using importance sampling and building a non-parametric model of the optimization surface. The paper is not concerned with optimization itself. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_answer(docs=top_docs,  query=FOLLOW_UP_QUESTION, language=\"English\",deployment=MODEL, chain_type=chain_type)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035fa6e6-226c-400f-a504-30255385f43b",
   "metadata": {},
   "source": [
    "Until now we just have the same as the prior Notebook 03: results from Azure Search enhanced by OpenAI model, with no memory\n",
    "\n",
    "**Now let's add memory to it:**\n",
    "\n",
    "Reference: https://python.langchain.com/en/latest/modules/memory/examples/adding_memory_chain_multiple_inputs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d98b876e-d264-48ae-b5ed-9801d6a9152b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning has been successfully used in a variety of applications, including routing and playing games such as backgammon, chess, checkers, and Othello at a high level. The focus of research in reinforcement learning is on designing algorithms for an agent interacting with an environment to optimize a long-term return. While there is no specific text in the provided document that directly lists use cases for reinforcement learning, it is a versatile technique that can be applied to a wide range of problems. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory object, which is neccessary to track the inputs/outputs and hold a conversation.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\")\n",
    "\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf28927b-d9ee-4412-bb07-13e055e832a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize for any confusion. What I meant to say is that while there is no specific text in the provided documents that directly list use cases for reinforcement learning, it is a versatile technique that can be applied to a wide range of problems. Is there anything else I can help you with?\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3830b0b8-0ca2-4d0a-9747-f6273368002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're welcome! Is there anything else I can assist you with?\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(docs=top_docs, query=\"Thank you\", language=\"English\", deployment=MODEL, chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e732b-3c8c-4df3-8fcb-c3d01e7bec74",
   "metadata": {},
   "source": [
    "Let's check our memory to see that it's keeping the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1279692c-7eb0-4300-8a66-c7025f02c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Tell me some use cases for reinforcement learning?\\nAI: Reinforcement learning has been successfully used in a variety of applications, including routing and playing games such as backgammon, chess, checkers, and Othello at a high level. The focus of research in reinforcement learning is on designing algorithms for an agent interacting with an environment to optimize a long-term return. While there is no specific text in the provided document that directly lists use cases for reinforcement learning, it is a versatile technique that can be applied to a wide range of problems. \\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf\\nHuman: Can you rephrase what you just said?\\nAI: I apologize for any confusion. What I meant to say is that while there is no specific text in the provided documents that directly list use cases for reinforcement learning, it is a versatile technique that can be applied to a wide range of problems. Is there anything else I can help you with?\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf\\nHuman: Thank you\\nAI: You're welcome! Is there anything else I can assist you with?\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87405173",
   "metadata": {},
   "source": [
    "## Using CosmosDB as persistent memory\n",
    "\n",
    "In previous cell we have added local RAM memory to our chatbot. However, it is not persistent, it gets deleted once the app user's session is terminated. It is necessary then to use a Database for persistent storage of each of the bot user conversations, not only for Analytics and Auditing, but also if we wisg to provide recommendations. \n",
    "\n",
    "Here we will store the conversation history into CosmosDB for future auditing purpose.\n",
    "We will use a class in LangChain use CosmosDBChatMessageHistory, see [HERE](https://python.langchain.com/en/latest/_modules/langchain/memory/chat_message_histories/cosmos_db.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7131daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CosmosDB instance from langchain cosmos class.\n",
    "\n",
    "SESSION_ID = '001'  # this is string value, normally you need to provide the user session id.\n",
    "USER_ID = 'dummy01' # this is string value, normally you need to provide the user id.\n",
    "\n",
    "cosmos = CosmosDBChatMessageHistory(\n",
    "    cosmos_endpoint=AZURE_COSMOSDB_ENDPOINT,\n",
    "    cosmos_database=AZURE_COSMOSDB_NAME,\n",
    "    cosmos_container=AZURE_COSMOSDB_CONTAINER_NAME,\n",
    "    connection_string=AZURE_COMOSDB_CONNECTION_STRING,\n",
    "    session_id=SESSION_ID,\n",
    "    user_id=USER_ID\n",
    "    )\n",
    "\n",
    "# prepare the cosmosdb instance\n",
    "cosmos.prepare_cosmos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d87cc7c6-5ef1-4492-b133-9f63a392e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or Memory Object\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key=\"question\",chat_memory=cosmos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27ceb47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning can be used in many applications, including routing. Some examples of reinforcement learning algorithms for routing are the ant-based algorithms of Subramanian et al. and the stigmergetic routing framework described in [10]. Reinforcement learning focuses on designing algorithms for an agent interacting with an environment, to adjust its behavior in such a way as to optimize a long-term return. This means searching for an optimal behavior in a class of behaviors. The interaction between agent and environment is modeled by a Markov decision process (mdp). The learning system does not know the correct behavior, or the true model of the environment it interacts with. Given the sensation of the environment state as an input, the agent chooses the action according to some rule, often called a policy. This action constitutes the output. The effectiveness of the action taken and its effect on the environment is communicated to the agent through a scalar value (reinforcement signal). However, there is no direct answer to the question in the given portion of the document. \\n\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing using our Question\n",
    "response = get_answer(docs=top_docs, query=QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                        memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5ff826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize for the confusion. In my previous response, I explained that reinforcement learning is a type of machine learning that focuses on designing algorithms for an agent interacting with an environment, to adjust its behavior in such a way as to optimize a long-term return. The interaction between agent and environment is modeled by a Markov decision process (mdp). The learning system does not know the correct behavior, or the true model of the environment it interacts with. Given the sensation of the environment state as an input, the agent chooses the action according to some rule, often called a policy. This action constitutes the output. The effectiveness of the action taken and its effect on the environment is communicated to the agent through a scalar value (reinforcement signal). As for use cases, reinforcement learning can be used in many applications, including routing. Some examples of reinforcement learning algorithms for routing are the ant-based algorithms of Subramanian et al. and the stigmergetic routing framework described in [10]. However, I did not provide a specific answer to your question. Could you please clarify what you would like me to rephrase? \\n\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we add a follow up question:\n",
    "response = get_answer(docs=top_docs, query=FOLLOW_UP_QUESTION, language=\"English\", deployment=MODEL, chain_type=chain_type, \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be1620fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're welcome! If you have any further questions, please let me know.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another follow up query\n",
    "response = get_answer(docs=top_docs, query=\"Thank you\", language=\"English\", deployment=MODEL, chain_type=chain_type,  \n",
    "                      memory=memory)\n",
    "response['output_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc5ac98",
   "metadata": {},
   "source": [
    "Let's check our Azure CosmosDB to see the whole conversation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d7688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me some use cases for reinforcement learning?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='Reinforcement learning can be used in many applications, including routing. Some examples of reinforcement learning algorithms for routing are the ant-based algorithms of Subramanian et al. and the stigmergetic routing framework described in [10]. Reinforcement learning focuses on designing algorithms for an agent interacting with an environment, to adjust its behavior in such a way as to optimize a long-term return. This means searching for an optimal behavior in a class of behaviors. The interaction between agent and environment is modeled by a Markov decision process (mdp). The learning system does not know the correct behavior, or the true model of the environment it interacts with. Given the sensation of the environment state as an input, the agent chooses the action according to some rule, often called a policy. This action constitutes the output. The effectiveness of the action taken and its effect on the environment is communicated to the agent through a scalar value (reinforcement signal). However, there is no direct answer to the question in the given portion of the document. \\n\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Can you rephrase what you just said?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='I apologize for the confusion. In my previous response, I explained that reinforcement learning is a type of machine learning that focuses on designing algorithms for an agent interacting with an environment, to adjust its behavior in such a way as to optimize a long-term return. The interaction between agent and environment is modeled by a Markov decision process (mdp). The learning system does not know the correct behavior, or the true model of the environment it interacts with. Given the sensation of the environment state as an input, the agent chooses the action according to some rule, often called a policy. This action constitutes the output. The effectiveness of the action taken and its effect on the environment is communicated to the agent through a scalar value (reinforcement signal). As for use cases, reinforcement learning can be used in many applications, including routing. Some examples of reinforcement learning algorithms for routing are the ant-based algorithms of Subramanian et al. and the stigmergetic routing framework described in [10]. However, I did not provide a specific answer to your question. Could you please clarify what you would like me to rephrase? \\n\\nSOURCES: https://demodatasetsp.blob.core.windows.net/arxivcs/0207/0207073v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0204/0204040v1.pdf, https://demodatasetsp.blob.core.windows.net/arxivcs/0105/0105027v1.pdf', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Thank you', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\"You're welcome! If you have any further questions, please let me know.\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load message from cosmosdb\n",
    "cosmos.load_messages()\n",
    "cosmos.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e30694-ae2a-47bb-a5c7-db51ecdbba1e",
   "metadata": {},
   "source": [
    "![CosmosDB Memory](./images/cosmos-chathistory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789cada-23a3-451a-a91a-0906ceb0bd14",
   "metadata": {},
   "source": [
    "# Summary\n",
    "##### Adding memory to our application allows the user to have a conversation, however this feature is not something that comes with the LLM, but instead, memory is something that we must provide to the LLM in form of context of the question.\n",
    "\n",
    "We added persitent memory using CosmosDB.\n",
    "\n",
    "We also can notice that the current chain that we are using is smart, but not that much. Although we have given memory to it, it searches for similar docs everytime, it struggles to respond to prompts like: Hello, Thank you, Bye, What's your name, What's the weather and any other task that is not search in the knowledge base.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c629ebf4-aced-45b7-a6a2-315810d37d48",
   "metadata": {},
   "source": [
    "# NEXT\n",
    "We know now how to do a Smart Search Engine that can power a chatbot!! great!\n",
    "\n",
    "But, does this solve all the possible scenarios that a virtual assistant will require?  **What about if the answer to the Smart Search Engine is not related to text, but instead requires to look into tabular data?** The next notebook 05 explains and solves the tabular problem and the concept of Agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
